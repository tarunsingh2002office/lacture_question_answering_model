{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a34f7f00",
   "metadata": {},
   "source": [
    "# Making the model\n",
    "\n",
    "- Logic/changes\n",
    "    - using large models\n",
    "    - First generating a detailed page summary(by giving page text and cumulative summary) then using this page summary and cumulative summary we generate the question(also answer and answer explaintaion)\n",
    "    - Removing validation layer\n",
    "    - Summarize this detailed summary \n",
    "    - then adding this page summary also to the cumulative summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a5251f",
   "metadata": {},
   "source": [
    "### Basic imports and pdf spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9780987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.schema.runnable import RunnableParallel\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import PDFMinerLoader\n",
    "from langchain_core.runnables.passthrough import RunnableAssign\n",
    "\n",
    "load_dotenv(override=True)\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "\n",
    "input_pdf_path = Path(r\"C:\\Users\\USER\\Desktop\\QA-Model\\data\\movie1\\avengersEndgameScript.pdf\")  # Replace with your PDF path\n",
    "pdf_output_folder = Path(r\"C:\\Users\\USER\\Desktop\\QA-Model\\data\\movie1\\split_pdf\")  # Replace with your output folder path\n",
    "output_folder = Path(r\"C:\\Users\\USER\\Desktop\\QA-Model\\data\\movie1\\output\")\n",
    "cumulative_detailed_summary_file = output_folder / \"cumulative_detailed_summary.txt\"\n",
    "cumulative_concise_summary_file = output_folder / \"cumulative_concise_summary.txt\"\n",
    "\n",
    "# Ensure the output folder exists\n",
    "pdf_output_folder.mkdir(parents=True, exist_ok=True)\n",
    "output_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ace84e0",
   "metadata": {},
   "source": [
    "### Spliting the pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffa1f9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_pdf(input_pdf_path, output_folder):\n",
    "    # Open the PDF file\n",
    "    reader = PdfReader(input_pdf_path)\n",
    "    total_pages = len(reader.pages)\n",
    "    \n",
    "    # Iterate through all pages\n",
    "    for i in range(total_pages):\n",
    "        writer = PdfWriter()\n",
    "        writer.add_page(reader.pages[i])  # Add one page to the writer\n",
    "        \n",
    "        # Generate the output file name\n",
    "        output_file_path = output_folder / f\"page_{i + 1}.pdf\"\n",
    "        with output_file_path.open(\"wb\") as output_file:\n",
    "            writer.write(output_file)\n",
    "    return total_pages\n",
    "\n",
    "total_pdfs=split_pdf(input_pdf_path, pdf_output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022162b3",
   "metadata": {},
   "source": [
    "### Getting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f66d3dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_generation_model = ChatOpenAI(model=\"o4-mini-2025-04-16\") #both the model does not support custom temperature values and only allows the default value of 1\n",
    "summary_generation_model = ChatOpenAI(model=\"gpt-4.1-mini-2025-04-14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4378ff55",
   "metadata": {},
   "source": [
    "### Getting the output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abfb9848",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_json_schema = {\n",
    "    \"title\": \"question_answers_and_explanations\",   \n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"all_questions\": {                        \n",
    "            \"type\": \"array\",\n",
    "            \"items\": {                        \n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"question\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Compose a question that can be answered with a simple Yes or No\"\n",
    "                    },\n",
    "                    \"correct_answer\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"Yes\", \"No\"],\n",
    "                        \"description\": \"Return the correct answer to the question\"\n",
    "                    },\n",
    "                    \"answer_explanation\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Write the explanation for the correct answer\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"question\", \"correct_answer\", \"answer_explanation\"]\n",
    "            },\n",
    "            \"description\": \"This array contains all the questions, correct answers and explanations\",\n",
    "        },\n",
    "        \"Page_interesting_rating\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"],\n",
    "            \"description\": \"\"\"\n",
    "RUTHLESSLY rate 1-10 CURRENT PAGE engagement (MUST BE HYPER-CRITICAL):\n",
    "\n",
    "10-Point Reality Check:\n",
    "10 = Story-defining climax (ONLY 1-2x per entire story)\n",
    "9 = Genre-changing twist (alters fundamental plot trajectory)\n",
    "8 = Protagonist life-threatening crisis (permanent consequences)\n",
    "7 = Major character betrayal/irreversible decision\n",
    "6 = Standard action scene (no lasting story impact)\n",
    "5 = Routine character development (backstory reveals)\n",
    "4 = Transitional dialogue (moving between locations)\n",
    "3 = Atmospheric descriptions (weather, environments)\n",
    "2 = Filler content (characters eating/sleeping)\n",
    "1 = Pure mechanical transition (\"They left the building\")\n",
    "\n",
    "Rating Restrictions:\n",
    "- 9-10: Reserved for pages that would make viewers gasp aloud\n",
    "- 7-8: Requires permanent plot/relationship changes\n",
    "- 5-6: Default for competent but unremarkable pages\n",
    "- 1-4: For pages authors would consider deleting\n",
    "\n",
    "Anti-Bias Rules:\n",
    "❌ Never rate based on previous/future pages\n",
    "❌ No extra points for \"setup\" or \"foreshadowing\"\n",
    "❌ Dialogue-heavy ≠ automatically interesting\n",
    "⛔ If unsure between two numbers, PICK THE LOWER ONE\n",
    "\n",
    "Distribution Guidance:\n",
    "• 9-10: Extreamly rare\n",
    "• 7-8: Very rare\n",
    "• 1-6: Common\n",
    "\"\"\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"all_questions\", \"Page_interesting_rating\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8a3d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_json_schema = {\n",
    "    \"title\": \"detailed_summary_and_concise_summary\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"detail_page_summary\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Comprehensive summary including characters, dialogue, actions, and plot details\"\n",
    "        },\n",
    "        \"concise_page_summary\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Condensed summary focusing only on major plot developments and key actions (3-5 sentences max)\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"detail_page_summary\", \"concise_page_summary\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cea69be",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_question_generation_model = question_generation_model.with_structured_output(question_json_schema)\n",
    "structured_summary_generation_model = summary_generation_model.with_structured_output(summary_json_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9401184",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract = RunnableLambda(lambda x: {\n",
    "    \"page_text\": x[\"page_text\"],\n",
    "    \"cumulative_concise_summary\": x[\"cumulative_concise_summary\"],\n",
    "    \"detail_page_summary\": x[\"both_summary\"][\"detail_page_summary\"],\n",
    "    \"concise_page_summary\": x[\"both_summary\"][\"concise_page_summary\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872985fb",
   "metadata": {},
   "source": [
    "### Making the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f58d2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_prompt = PromptTemplate(\n",
    "    input_variables=[\"detail_page_summary\", \"cumulative_concise_summary\"],\n",
    "    template=(\"\"\"Generate 10 diverse questions, answer and answer explanation by following these STRICT RULES:\n",
    "   \n",
    "### VALIDATION RULES\n",
    "\n",
    "   1. Questions must be answerable with Yes/No.\n",
    "   2. Base questions only on explicit information presnt in current page summary.\n",
    "   3. If insufficient information for 10 questions, generate fewer questions.\n",
    "   4. Ensure answers are unambiguous.\n",
    "   5. Avoid similar questions about the same fact\n",
    "   6. Include varied question types (actions, dialogue, presence, etc.)\n",
    "   7. For answer explanations:\n",
    "      - MUST use: \"In the scene...\", \"As shown...\", \"Through dialogue...\", \"Visually we see...\"\n",
    "      - BANNED PHRASES: \"summary\", \"script\", \"page\", \"document\", \"text\"\n",
    "   8. If answer cannot be DIRECTLY VERIFIED from given content:\n",
    "      - DO NOT create the question\n",
    "   9. Absolute prohibitions:\n",
    "      - No assumptions beyond given context\n",
    "\n",
    "\n",
    "### CONTEXT \n",
    "\n",
    "   Previous Story Context (for reference only):\n",
    "   \\n{cumulative_concise_summary}\\n\n",
    "\n",
    "   Current Page Summary:\n",
    "   \\n{detail_page_summary}\\n\n",
    "\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e744a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_prompt = PromptTemplate(\n",
    "    input_variables=[\"page_text\", \"cumulative_concise_summary\"],\n",
    "    template=\"\"\"Analyze this movie script page with STRICT ADHERENCE TO VISIBLE CONTENT ONLY to generate a DETAILED SUMMARY and CONCISE SUMMARY.\n",
    "\n",
    "# DETAILED SUMMARY\n",
    "- Include:\n",
    "    1. Characters:\n",
    "        - ONLY newly introduced characters with DESCRIPTIONS EXPLICITLY STATED\n",
    "        - If none: \"No new characters introduced\"\n",
    "    2. Dialogue\n",
    "        - EXACT quotes from 3-5 CRUCIAL exchanges\n",
    "        - If none: \"No key dialogue exchanges\"\n",
    "    3. Actions:\n",
    "        - Specific actions taken by characters\n",
    "        - If none: \"No significant physical actions\"\n",
    "    4. Plot:\n",
    "        - Important plot developments\n",
    "        - If none: \"No plot advancements\"\n",
    "    5. Locations:\n",
    "        - Scene locations and time references\n",
    "        - If vague: \"Location and time unspecified\"\n",
    "    6. Background:\n",
    "        - Background information\n",
    "        - If none: \"No background information\"\n",
    "- Absolute Prohibitions:\n",
    "    1. Using Context from previous page to generate DeTAILED SUMMARY\n",
    "    2. NO character psychology interpretation\n",
    "    3. NO dialogue paraphrasing\n",
    "    4. NO location extrapolation\n",
    "    5. NO time assumptions\n",
    "- Format with markdown headers:\n",
    "  ### Characters\n",
    "  ### Dialogue\n",
    "  ### Actions\n",
    "  ### Plot\n",
    "  ### Locations\n",
    "  ### Background\n",
    "\n",
    "# CONSISTENT SUMMARY\n",
    "- Construction Rules:\n",
    "    1. MUST connect to previous context using TEMPORAL MARKERS:\n",
    "        - \"Following [previous event]...\"\n",
    "        - \"While [ongoing action]...\"\n",
    "        - \"[Time] later...\"\n",
    "    2. If no connection possible: Start with \"Meanwhile...\" using current facts\n",
    "    3. Maintain consistent character voices\n",
    "    4. Highlight plot consequences\n",
    "    5. ONLY use CURRENT PAGE FACTS + EXPLICIT PREVIOUS CONTEXT\n",
    "- Output Requirements:\n",
    "    - Novel-style prose\n",
    "    - 5-7 sentences \n",
    "    - Focus on overall storyline\n",
    "    - Cause-effect chain emphasis\n",
    "\n",
    "# Fallback Protocol\n",
    "    - For ANY ambiguous/missing information:\n",
    "        1. Acknowledge uncertainty explicitly\n",
    "        2. DO NOT attempt to \"fill in gaps\"\n",
    "        3. Use phrase: \"Not explicitly stated in scene\"\n",
    "    - If page contains:\n",
    "        1. Blank page -> Return empty summaries with \"Empty page\" note\n",
    "        2. Transition scenes with no developments -> Return empty summaries with \"Scene transition\" note\n",
    "        3. Copyright notices -> Return empty summaries with \"Copyright notice\" note\n",
    "\n",
    "# CONTEXT\n",
    "- Context from previous pages (for reference only):\n",
    "\\n{cumulative_concise_summary}\\n\n",
    "\n",
    "- Current Page Content:\n",
    "\\n{page_text}\\n\n",
    "\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0945d7",
   "metadata": {},
   "source": [
    "### Making the model in a loop with chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "953ea80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_concise_summary = \"\"\n",
    "cumulative_detailed_summary = \"\"\n",
    "for i in range(total_pdfs):\n",
    "    current_page_number = i + 1\n",
    "\n",
    "    pdf_name = pdf_output_folder / f\"page_{current_page_number}.pdf\"\n",
    "    loader = PDFMinerLoader(pdf_name)\n",
    "    docs = loader.load()\n",
    "    page_text = docs[0].page_content\n",
    "\n",
    "    summary_chain = summary_prompt | structured_summary_generation_model\n",
    "    question_chain = question_prompt | structured_question_generation_model\n",
    "\n",
    "    chain1 = RunnableAssign(RunnableParallel({\"both_summary\": summary_chain}))\n",
    "    chain2 = RunnableAssign(RunnableParallel({\"question\": question_chain}))\n",
    "\n",
    "    final_chain = chain1 | extract | chain2 \n",
    "    result = final_chain.invoke({\"page_text\":page_text,\"cumulative_concise_summary\":cumulative_concise_summary})\n",
    "    \n",
    "    question = result[\"question\"]\n",
    "    concise_page_summary = result[\"concise_page_summary\"]\n",
    "    detailed_page_summary = result[\"detail_page_summary\"]\n",
    "\n",
    "    # Save results\n",
    "    page_folder = output_folder / f\"page_{current_page_number}\"\n",
    "    page_folder.mkdir(parents=True, exist_ok=True)\n",
    "    question_json = page_folder / \"question.json\"\n",
    "\n",
    "    with question_json.open(\"w\") as f:\n",
    "        json.dump(question, f, indent=4)\n",
    "    \n",
    "    cumulative_concise_summary += f\"\\n\\nPage {current_page_number} Summary:\\n{concise_page_summary}\\n\"\n",
    "    cumulative_detailed_summary += f\"\\n\\nPage {current_page_number} Summary:\\n{detailed_page_summary}\\n\"\n",
    "\n",
    "    with cumulative_detailed_summary_file.open(\"w\") as f:\n",
    "        f.write(cumulative_detailed_summary)\n",
    "    \n",
    "    with cumulative_concise_summary_file.open(\"w\") as f:\n",
    "        f.write(cumulative_concise_summary) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70a46f0",
   "metadata": {},
   "source": [
    "### Testing token size for each summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11179f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= summary_generation_model.get_num_tokens(cumulative_detailed_summary)\n",
    "b= summary_generation_model.get_num_tokens(cumulative_concise_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dc2619b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46012\n",
      "14434\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
